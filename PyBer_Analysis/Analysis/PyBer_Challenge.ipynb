{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Matplotlib inline magic command\n",
    "%matplotlib inline\n",
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to load\n",
    "city_data_to_load = \"Resources/city_data.csv\"\n",
    "ride_data_to_load = \"Resources/ride_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Resources/city_data.csv' does not exist: b'Resources/city_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e6e8e9e9ad6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read the city data file and store it in a pandas DataFrame.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcity_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity_data_to_load\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcity_data_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Resources/city_data.csv' does not exist: b'Resources/city_data.csv'"
     ]
    }
   ],
   "source": [
    "# Read the city data file and store it in a pandas DataFrame.\n",
    "city_data_df = pd.read_csv(city_data_to_load)\n",
    "city_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ride data file and store it in a pandas DataFrame.\n",
    "ride_data_df = pd.read_csv(ride_data_to_load)\n",
    "ride_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns and the rows that are not null.\n",
    "city_data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns and the rows that are not null.\n",
    "city_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data types of each column.\n",
    "city_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values of the type of city.\n",
    "city_data_df[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of data points from the Urban cities.\n",
    "sum(city_data_df[\"type\"]==\"Urban\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns and the rows that are not null.\n",
    "ride_data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns and the rows that are not null.\n",
    "ride_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data types of each column.\n",
    "ride_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data into a single dataset\n",
    "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "pyber_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Urban city DataFrame.\n",
    "urban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Urban\"]\n",
    "urban_cities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Suburban and Rural city DataFrames.\n",
    "suburban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Suburban\"]\n",
    "rural_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Rural\"]\n",
    "rural_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rides for urban cities.\n",
    "urban_ride_count = urban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
    "urban_ride_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the suburban and rural ride count.\n",
    "suburban_ride_count = suburban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
    "\n",
    "rural_ride_count = rural_cities_df.groupby([\"city\"]).count()[\"ride_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average fare for each city in the urban cities.\n",
    "urban_avg_fare = urban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
    "urban_avg_fare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average fare for each city in the suburban and rural cities.\n",
    "suburban_avg_fare = suburban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
    "rural_avg_fare = rural_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
    "suburban_avg_fare\n",
    "rural_avg_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average number of drivers for each urban city.\n",
    "urban_driver_count = urban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
    "urban_driver_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average number of drivers for each city for the suburban and rural cities.\n",
    "suburban_driver_count = suburban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
    "rural_driver_count = rural_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
    "suburban_driver_count\n",
    "rural_driver_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the scatter plots for urban cities.\n",
    "plt.scatter(urban_ride_count,\n",
    "      urban_avg_fare,\n",
    "      s=urban_driver_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the scatter plots for urban cities.\n",
    "plt.scatter(urban_ride_count,\n",
    "      urban_avg_fare,\n",
    "      s=10*urban_driver_count, c=\"coral\",\n",
    "      edgecolor=\"black\", linewidths=1,\n",
    "      alpha=0.8, label=\"Urban\")\n",
    "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
    "plt.ylabel(\"Average Fare ($)\")\n",
    "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
    "plt.grid(True)\n",
    "# Add the legend.\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the scatter plots for suburban cities.\n",
    "plt.scatter(suburban_ride_count,\n",
    "      suburban_avg_fare,\n",
    "      s=10*suburban_driver_count, c=\"skyblue\",\n",
    "      edgecolor=\"black\", linewidths=1,\n",
    "      alpha=0.8, label=\"Suburban\")\n",
    "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
    "plt.ylabel(\"Average Fare ($)\")\n",
    "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
    "plt.grid(True)\n",
    "# Add the legend.\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the scatter plots for rural cities.\n",
    "plt.scatter(rural_ride_count,\n",
    "      rural_avg_fare,\n",
    "      s=10*rural_driver_count, c=\"gold\",\n",
    "      edgecolor=\"black\", linewidths=1,\n",
    "      alpha=0.8, label=\"Rural\")\n",
    "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
    "plt.ylabel(\"Average Fare ($)\")\n",
    "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
    "plt.grid(True)\n",
    "# Add the legend.\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the scatter charts for each type of city.\n",
    "plt.scatter(urban_ride_count, \n",
    "      urban_avg_fare, \n",
    "      s=10*urban_driver_count, c=\"coral\", \n",
    "      edgecolor=\"black\", linewidths=1, \n",
    "      alpha=0.8, label=\"Urban\")\n",
    "\n",
    "plt.scatter(suburban_ride_count, \n",
    "      suburban_avg_fare, \n",
    "      s=10*suburban_driver_count, c=\"skyblue\", \n",
    "      edgecolor=\"black\", linewidths=1, \n",
    "      alpha=0.8, label=\"Suburban\")\n",
    "\n",
    "plt.scatter(rural_ride_count, \n",
    "      rural_avg_fare, \n",
    "      s=10*rural_driver_count, c=\"gold\", \n",
    "      edgecolor=\"black\", linewidths=1, \n",
    "      alpha=0.8, label=\"Rural\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the scatter charts for each city type.\n",
    "plt.subplots(figsize=(10, 6))\n",
    "plt.scatter(urban_ride_count, \n",
    "      urban_avg_fare, \n",
    "      s=10*urban_driver_count, c=\"coral\", \n",
    "      edgecolor=\"black\", linewidths=1, \n",
    "      alpha=0.8, label=\"Urban\")\n",
    "\n",
    "plt.scatter(suburban_ride_count, \n",
    "      suburban_avg_fare, \n",
    "      s=10*suburban_driver_count, c=\"skyblue\", \n",
    "      edgecolor=\"black\", linewidths=1, \n",
    "      alpha=0.8, label=\"Suburban\")\n",
    "\n",
    "plt.scatter(rural_ride_count, \n",
    "      rural_avg_fare, \n",
    "      s=10*rural_driver_count, c=\"gold\", \n",
    "      edgecolor=\"black\", linewidths=1, \n",
    "      alpha=0.8, label=\"Rural\")\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
    "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
    "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Add the legend.\n",
    "# Create a legend\n",
    "lgnd = plt.legend(fontsize=\"12\", mode=\"Expanded\",\n",
    "         scatterpoints=1, loc=\"best\", title=\"City Types\")\n",
    "lgnd.legendHandles[0]._sizes = [75]\n",
    "lgnd.legendHandles[1]._sizes = [75]\n",
    "lgnd.legendHandles[2]._sizes = [75]\n",
    "lgnd.get_title().set_fontsize(12)\n",
    "# Incorporate a text label about circle size.\n",
    "plt.text(42, 35, \"Note:\\nCircle size correlates\\nwith driver count per city.\", fontsize=\"12\")\n",
    "# Save the figure.\n",
    "plt.savefig(\"analysis/Fig1.png\")\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics.\n",
    "urban_cities_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburban_ride_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_ride_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the ride count for each city type.\n",
    "round(urban_ride_count.mean(),2), round(suburban_ride_count.mean(),2), round(rural_ride_count.mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode of the ride count for the urban cities.\n",
    "urban_ride_count.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburban_ride_count.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the measures of central tendency for the ride count for the urban cities.\n",
    "mean_urban_ride_count = np.mean(urban_ride_count)\n",
    "print(f\"The mean for the ride counts for urban trips is {mean_urban_ride_count:.2f}.\")\n",
    "\n",
    "median_urban_ride_count = np.median(urban_ride_count)\n",
    "print(f\"The median for the ride counts for urban trips is {median_urban_ride_count}.\")\n",
    "\n",
    "mode_urban_ride_count = sts.mode(urban_ride_count)\n",
    "print(f\"The mode for the ride counts for urban trips is {mode_urban_ride_count}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_ride_count.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fares for the urban cities.\n",
    "urban_fares = urban_cities_df[\"fare\"]\n",
    "urban_fares.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the measures of central tendency for the average fare for the urban cities.\n",
    "mean_urban_fares = np.mean(urban_fares)\n",
    "print(f\"The mean fare price for urban trips is ${mean_urban_fares:.2f}.\")\n",
    "\n",
    "median_urban_fares = np.median(urban_fares)\n",
    "print(f\"The median fare price for urban trips is ${median_urban_fares:.2f}.\")\n",
    "\n",
    "mode_urban_fares = sts.mode(urban_fares)\n",
    "print(f\"The mode fare price for urban trips is {mode_urban_fares}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the driver count data from the urban cities.\n",
    "urban_drivers = urban_cities_df['driver_count']\n",
    "urban_drivers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box-and-whisker plot for the urban cities ride count.\n",
    "x_labels = [\"Urban\"]\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(urban_ride_count, labels=x_labels)\n",
    "# Add the title, y-axis label and grid.\n",
    "ax.set_title('Ride Count Data (2019)')\n",
    "ax.set_ylabel('Number of Rides')\n",
    "ax.set_yticks(np.arange(10, 41, step=2.0))\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all ride count box-and-whisker plots to the same graph.\n",
    "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
    "ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_title('Ride Count Data (2019)',fontsize=20)\n",
    "ax.set_ylabel('Number of Rides',fontsize=14)\n",
    "ax.set_xlabel(\"City Types\",fontsize=14)\n",
    "ax.boxplot(ride_count_data, labels=x_labels)\n",
    "ax.set_yticks(np.arange(0, 45, step=3.0))\n",
    "ax.grid()\n",
    "# Save the figure.\n",
    "plt.savefig(\"analysis/Fig2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the city that matches 39.\n",
    "urban_city_outlier = urban_ride_count[urban_ride_count==39].index[0]\n",
    "print(f\"{urban_city_outlier} has the highest rider count.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box-and-whisker plot for the urban fare data.\n",
    "x_labels = [\"Urban\"]\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(urban_fares, labels=x_labels)\n",
    "# Add the title, y-axis label and grid.\n",
    "ax.set_title('Ride Fare Data (2019)')\n",
    "ax.set_ylabel('Fare($USD)')\n",
    "ax.set_yticks(np.arange(0, 51, step=5.0))\n",
    "ax.grid()\n",
    "plt.show()\n",
    "print(\"Summary Statistics\")\n",
    "urban_fares.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the box-and-whisker plot for the urban driver count data.\n",
    "x_labels = [\"Urban\"]\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(urban_drivers,labels=x_labels)\n",
    "# Add the title, y-axis label and grid.\n",
    "ax.set_title('Driver Count Data (2019)')\n",
    "ax.set_ylabel('Number of Drivers)')\n",
    "ax.set_yticks(np.arange(0, 90, step=5.0))\n",
    "ax.grid()\n",
    "plt.show()\n",
    "print(\"Summary Statistics\")\n",
    "urban_drivers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of the fares for each city type.\n",
    "sum_fares_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
    "sum_fares_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of all the fares.\n",
    "total_fares = pyber_data_df[\"fare\"].sum()\n",
    "total_fares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of fare for each city type.\n",
    "type_percents = 100 * sum_fares_by_type / total_fares\n",
    "type_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of fare for each city type.\n",
    "type_percents = 100 * pyber_data_df.groupby([\"type\"]).sum()[\"fare\"] / pyber_data_df[\"fare\"].sum()\n",
    "type_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the percentage of fares by city type pie chart.\n",
    "plt.pie(type_percents, labels=[\"Rural\", \"Suburban\", \"Urban\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the percentage of fares by city type pie chart.\n",
    "plt.pie(type_percents,\n",
    "    labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
    "    colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
    "    explode=[0, 0, 0.1],\n",
    "    autopct='%1.1f%%',\n",
    "    shadow=True, startangle=150)\n",
    "plt.title(\"% of Total Fares by City Type\")\n",
    "# Show Figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mpl to change the plot configurations using rcParams.\n",
    "import matplotlib as mpl\n",
    "# Build Pie Chart\n",
    "plt.subplots(figsize=(10, 6))\n",
    "plt.pie(type_percents,\n",
    "    labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
    "    colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
    "    explode=[0, 0, 0.1],\n",
    "    autopct='%1.1f%%',\n",
    "    shadow=True, startangle=150)\n",
    "plt.title(\"% of Total Fares by City Type\")\n",
    "# Change the default font size from 10 to 14.\n",
    "mpl.rcParams['font.size'] = 14\n",
    "# Save Figure\n",
    "plt.savefig(\"analysis/Fig5.png\")\n",
    "# Show Figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyber_data_df.groupby([\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyber_data_df[\"ride_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of rides for each city type.\n",
    "ride_percents = 100 * pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"] / pyber_data_df[\"ride_id\"].count()\n",
    "ride_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build percentage of rides by city type pie chart.\n",
    "plt.subplots(figsize=(10, 6))\n",
    "plt.pie(ride_percents,\n",
    "    labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
    "    colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
    "    explode=[0, 0, 0.1],\n",
    "    autopct='%1.1f%%',\n",
    "    shadow=True, startangle=150)\n",
    "plt.title(\"% of Total Rides by City Type\")\n",
    "# Change the default font size from 10 to 14.\n",
    "mpl.rcParams['font.size'] = 14\n",
    "# Save Figure\n",
    "plt.savefig(\"analysis/Fig6.png\")\n",
    "# Show Figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of drivers for each city type.\n",
    "driver_percents = 100 * pyber_data_df.groupby([\"type\"]).sum()[\"driver_count\"] / pyber_data_df[\"driver_count\"].sum()\n",
    "driver_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build percentage of rides by city type pie chart.\n",
    "plt.subplots(figsize=(10, 6))\n",
    "plt.pie(driver_percents,\n",
    "    labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
    "    colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
    "    explode=[0, 0, 0.1],\n",
    "    autopct='%1.1f%%',\n",
    "    shadow=True, startangle=165)\n",
    "plt.title(\"% of Total Rides by City Type\")\n",
    "# Change the default font size from 10 to 14.\n",
    "mpl.rcParams['font.size'] = 14\n",
    "# Save Figure\n",
    "plt.savefig(\"analysis/Fig7.png\")\n",
    "# Show Figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge\n",
    "# Directive: Use functions on a dataFrame\n",
    "# Create a new DataFrame from multiple groupby() series.\n",
    "# Format columns of a DataFrame\n",
    "# Create multiple line graph\n",
    "# Annotate and apply stylings to the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary DataFramew that includes total rides, total drivers, total fares, \n",
    "\n",
    "pyber_data_df.rename(columns={'city': 'City', 'date': 'Date', 'fare': 'Fare', 'ride_id': 'Ride ID', 'driver_count': 'No. Drivers', 'type': 'City Type'}, inplace=True)\n",
    "pyber_data_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total rides for each city type\n",
    "#total_rides_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
    "#toal_rides_by_type\n",
    "\n",
    "total_drivers_by_type = pyber_data_df.groupby([\"City Type\"]).sum()[\"Ride ID\"] \n",
    "total_drivers_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total drivers for each city type\n",
    "total_drivers_by_type = city_data_df.groupby([\"type\"]).sum()[\"driver_count\"] \n",
    "total_drivers_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Fares\n",
    "#total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"] \n",
    "#total_fare_by_type\n",
    "pyber_data_df.groupby([\"City Type\"]).sum()[\"Fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average fare per driver for each city type\n",
    "avg_fare_per_driver = total_fare_by_type / total_drivers_by_type\n",
    "avg_fare_per_driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average fare per ride, and the average fare per driver by city type\n",
    "avg_fare_per_ride = total_fare_by_type / total_rides_by_type\n",
    "avg_fare_per_ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the index name\n",
    "pyber_ride_summary_df.dropna().iloc(0)\n",
    "pyber_ride_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new summery DataFrame which includes appropriate columns and formatting.\n",
    "pyber_ride_summary_df = pd.dataFrame({\"Total Rides\": total_rides_by_type, \"Total Drivers\": total_fare_by_type, \"Average Fare Per Ride\": Avg fare_per_ride, \"Average Fare per Driver\": avg_fare_per_driver})\n",
    "pyber_ride_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to the date column\n",
    "pyber_data_df.set_index(pyber_data_df['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for fares and include only date, city typ[e and fare columns using the \n",
    "#copy() method]\n",
    "pyber_cities_fares = pyber_data_df[['Date', 'City Type', 'Fare']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra date column\n",
    "pyber_cities_fares.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the date time datatype\n",
    "pyber_cities_fares.index = pd.to_datetime(pyber_data_df.index)\n",
    "pyber_cities_fares.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum() of fares by the type of city and date using groupby() to create a new DataFrame.\n",
    "sum_fare_by_type = pyber_cities_fares.groupby([\"City Type\", \"Date\"]).sum()[\"Fare\"]\n",
    "sum_fare_by_type.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index which is needed for a future step.\n",
    "sum_fare_by_type = sum_fare_by_type.reset_index()\n",
    "sum_fare_by_type.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table DataFrame with the date as the index, and columns City Type with fare for \n",
    "# each date in each row.  \n",
    "sum_fare_by_type_pivot = sum_fare_by_type.pivot(index=\"Date\", columns=\"City Type\")[\"Fare\"]\n",
    "sum_fare_by_type_pivot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from the pivot table Data Frame on the given dates.  See documnetation.\n",
    "fares_Jan_April = sum_fare_by_type_pivot.loc['2019-01-01':'2019-04-28']\n",
    "fares_Jan_April.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataFrame by setting the dataFrame you created with resample() in weekly bins, \n",
    "#and calculate the sum() of the fares for each week. \n",
    "pyber_ride_summary_df = pd.dataFrame({\"Total Rides\": total_rides_by_type, \"Total Drivers\": total_fare_by_type, \"Average Fare Per Ride\": Avg fare_per_ride, \"Average Fare per Driver\": avg_fare_per_driver})\n",
    "pyber_ride_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format the columns\n",
    "\n",
    "pyber_ride_su[\"Total Rides\"] = pyber_ride_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
    "pyber_ride_summary_df[\"Total Drivers\"] = pyber_ride_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
    "pyber_ride_summary_df[\"Total Fares\"] = pyber_ride_summary_df[\"Total Fares\"].map(\"{:,.2f}\".format)\n",
    "pyber_ride_summary_df[\"Average Fare per Ride\"] = pyber_ride_summary_df[\"Total Fare per Ride\"].map(\"{:,.2f}\".format)\n",
    "pyber_ride_summary_df[\"Average Fare per Driver\"] = pyber_ride_summary_df[\"Average Fare per Driver\"].map(\"{:,.2f}\".format)\n",
    "\n",
    "pyber_ride_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multiple line plot for the sum of the fares for each city type.\n",
    "#style\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "#colors\n",
    "colors = [[0,114/255,178/255], [213/255,94/255,0], [230/255,159/255,0]]\n",
    "\n",
    "#plot\n",
    "ax = slice_pivot_pyber_data.plot(kind = \"line\", lw=2, markersize=50, title='Total Fare By City Type', figsize = (12,3, grid)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel('Fare($USD)')\n",
    "plt.savefix(\"analysis\\Fig7.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the object oriented interface method, plot the DataFrame you \n",
    "# created using the df.plot() function.  Things to condsider, see documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a summary in ReadMe, and include the graph image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
